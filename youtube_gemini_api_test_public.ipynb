{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f3c291-8ca7-47d0-8eb4-fc9233c10905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cea85ad-0786-4475-ba8a-483ea7330275",
   "metadata": {},
   "outputs": [],
   "source": [
    "myKey = 'your_api_here'\n",
    "project_id = 'your_project_id_here'\n",
    "region = 'select_your_region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc5efff-5ee1-4fd5-a32c-ed514a1251c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a YouTube Data API service object.\n",
    "service = googleapiclient.discovery.build('youtube', 'v3', developerKey=myKey)\n",
    "\n",
    "# Define the search query and the number of results.\n",
    "search_query = 'google cloud' ### change this to be any search query you would like \n",
    "num_results = 10\n",
    "\n",
    "# Perform the search.\n",
    "request = service.search().list(\n",
    "    q=search_query,\n",
    "    relevanceLanguage='en',\n",
    "    part='snippet',\n",
    "    maxResults=num_results,\n",
    "    publishedAfter='2024-09-15T00:00:00Z')\n",
    "response = request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526833a0-c890-42b6-9c83-006fce68938a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: https://www.youtube.com/watch?v=cbcd6-m8sHg\n",
      "Video ID: https://www.youtube.com/watch?v=lvZk_sc8u5I\n",
      "Video ID: https://www.youtube.com/watch?v=AQX_rgL1gNw\n",
      "Video ID: https://www.youtube.com/watch?v=PLF8kUtXOsI\n",
      "Video ID: https://www.youtube.com/watch?v=OEwQ2-fkRag\n",
      "Video ID: https://www.youtube.com/watch?v=9dAx8bK3JlQ\n",
      "Video ID: https://www.youtube.com/watch?v=0aDJ6GqsJqc\n",
      "Video ID: https://www.youtube.com/watch?v=VWlwMlJtLn8\n",
      "Video ID: https://www.youtube.com/watch?v=sGvXO7CVwc0\n",
      "Video ID: https://www.youtube.com/watch?v=ZE8KgTxR6Bk\n",
      "['https://www.youtube.com/watch?v=cbcd6-m8sHg', 'https://www.youtube.com/watch?v=lvZk_sc8u5I', 'https://www.youtube.com/watch?v=AQX_rgL1gNw', 'https://www.youtube.com/watch?v=PLF8kUtXOsI', 'https://www.youtube.com/watch?v=OEwQ2-fkRag', 'https://www.youtube.com/watch?v=9dAx8bK3JlQ', 'https://www.youtube.com/watch?v=0aDJ6GqsJqc', 'https://www.youtube.com/watch?v=VWlwMlJtLn8', 'https://www.youtube.com/watch?v=sGvXO7CVwc0', 'https://www.youtube.com/watch?v=ZE8KgTxR6Bk']\n"
     ]
    }
   ],
   "source": [
    "video_ids = []\n",
    "for item in response['items']:  # Iterate through each search result\n",
    "    video_id = item['id']['videoId']  # Access the video ID within the nested dictionaries\n",
    "    video_id = str('https://www.youtube.com/watch?v=' + video_id)\n",
    "    video_ids.append(video_id)\n",
    "    print(f\"Video ID: {video_id}\")\n",
    "\n",
    "print(video_ids) #prints the video IDs in the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a690ad7e-aebc-438a-ab27-21016ad14c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, SafetySetting\n",
    "\n",
    "\n",
    "def generate(yt_link):\n",
    "    vertexai.init(project=project_id, location=region)\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.5-flash-001\",\n",
    "    )\n",
    "    text1 = \"\"\"add whatever query you would like here, what you would like gemini to searh for etc \"\"\" #### EDIT HERE\n",
    "    video1 = Part.from_uri(\n",
    "        mime_type=\"video/*\",\n",
    "        uri=yt_link,\n",
    "    )\n",
    "\n",
    "    generation_config = {\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "    }\n",
    "    responses = model.generate_content(\n",
    "        [text1, video1],\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    \n",
    "    r =[]\n",
    "    for response in responses:\n",
    "        r.append(response.text)\n",
    "    return(r)\n",
    "\n",
    "\n",
    "\n",
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "    SafetySetting(\n",
    "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0450b26b-2767-4a9a-a4fe-15dd0d4e127f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceUnavailable",
     "evalue": "503 The service is currently unavailable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:170\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     prefetch_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callable_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_prefetch_first_result_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_StreamingResponseIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefetch_first_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefetch_first\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:92\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__init__\u001b[0;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prefetch_first_result:\n\u001b[0;32m---> 92\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stored_first_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# It is possible the wrapped method isn't an iterable (a grpc.Call\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# for instance). If this happens don't store the first result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:540\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/grpc/_channel.py:966\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 966\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"The service is currently unavailable.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.184.95:443 {created_time:\"2024-09-25T20:54:56.153313295+00:00\", grpc_status:14, grpc_message:\"The service is currently unavailable.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m video_ids:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m#print(link)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     responses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     responses\u001b[38;5;241m.\u001b[39mappend(r)\n",
      "Cell \u001b[0;32mIn[31], line 31\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(yt_link)\u001b[0m\n\u001b[1;32m     22\u001b[0m responses \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[1;32m     23\u001b[0m     [text1, video1],\n\u001b[1;32m     24\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m     25\u001b[0m     safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[1;32m     26\u001b[0m     stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     30\u001b[0m r \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m responses:\n\u001b[1;32m     32\u001b[0m     r\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:781\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content_streaming\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    757\u001b[0m \n\u001b[1;32m    758\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;124;03m    A stream of GenerationResponse objects\u001b[39;00m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    774\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    775\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    776\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m     tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    780\u001b[0m )\n\u001b[0;32m--> 781\u001b[0m response_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response_stream:\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(chunk)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py:2250\u001b[0m, in \u001b[0;36mPredictionServiceClient.stream_generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2249\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2250\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2255\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2257\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:174\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[1;32m    171\u001b[0m         result, prefetch_first_result\u001b[38;5;241m=\u001b[39mprefetch_first\n\u001b[1;32m    172\u001b[0m     )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mServiceUnavailable\u001b[0m: 503 The service is currently unavailable."
     ]
    }
   ],
   "source": [
    "for link in video_ids:\n",
    "    #print(link)\n",
    "    responses = []\n",
    "    r = generate(link)\n",
    "    responses.append(r)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
